# safepyrun


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

*safepyrun* is an allowlist-based Python sandbox that lets LLMs execute
code safely(ish) in your real environment. Instead of isolating code in
a container (which cuts it off from the libraries, data, and tools it
actually needs) safepyrun runs in-process with controlled access to a
curated subset of Python’s stdlib, plus any functions you explicitly opt
in.

It’s the Python counterpart to
[safecmd](https://github.com/AnswerDotAI/safecmd), which does much the
same thing for bash.

## Installation

Install from [pypi](https://pypi.org/project/safepyrun/)

``` sh
$ pip install safepyrun
```

## Background

When an LLM needs to run code on your behalf, the standard advice is to
sandbox it in a container. The problem is that the whole reason you want
the LLM running code is so it can interact with your environment – your
files, your libraries, your running processes, your data. A
containerised sandbox either can’t access any of that (making it largely
useless) or requires complex volume mounts and dependency mirroring that
recreate your environment inside the container (which is fragile and
slow).

The obvious alternative is to just `exec` the LLM’s code directly in
your process. This gives full access to everything, but “everything”
includes
[`shutil.rmtree`](https://docs.python.org/3/library/shutil.html#shutil.rmtree),
[`os.remove`](https://docs.python.org/3/library/os.html#os.remove),
`subprocess.run("rm -rf /")`, and arbitrary network exfiltration. One
hallucinated cleanup step and you’ve lost files.

safepyrun takes a middle path. It runs the LLM’s code in your real
Python process, with access to your real objects, but interposes an
allowlist that controls which callables are accessible. The curated
default list covers a large and useful subset of the standard library
(string manipulation, math, JSON parsing, path inspection, data
structures, and so on) while excluding anything that writes to the
filesystem, spawns processes, or modifies system state. You can extend
the list for your own functions with a single
[`allow()`](https://AnswerDotAI.github.io/safepyrun/core.html#allow)
call.

The mechanism behind safepyrun is
[RestrictedPython](https://restrictedpython.readthedocs.io/), a
long-standing project that compiles Python source code into a modified
AST (Abstract Syntax Tree) where every attribute access, item access,
and iteration is routed through hook functions. This means that when the
LLM’s code does `obj.method()`, it doesn’t go directly to `method` – it
goes through a gatekeeper that checks whether that callable is on the
allowlist. The same applies to `getattr`, `getitem`, and `iter`, so
there’s no easy way to accidentally reach a dangerous function through
indirect access. safepyrun supplies these hook functions, wiring them up
to an allowlist of permitted callables.

Because a lot of modern Python code (and many LLM tool-calling
frameworks) is async, safepyrun also depends on
[restrictedpython-async](https://github.com/AnswerDotAI/restrictedpython-async),
which extends RestrictedPython to handle `await`, `async for`, and
`async with` expressions. Without this, any code that needs to call an
async function (which is increasingly common) would be blocked by the
sandbox.

A lot of the online discussion around RestrictedPython suggests it’s not
really useful for sandboxing, and that’s true if you’re trying to block
a determined adversary. But an LLM is not a determined adversary. It’s a
well-meaning but occasionally clumsy collaborator. The threat model is
completely different: you don’t need to prevent deliberate escape
attempts, you need to make it very unlikely that a hallucinated cleanup
step or a misunderstood request causes damage. This is the same
“safe-ish” philosophy used in
[safecmd](https://github.com/AnswerDotAI/safecmd) for bash.

Once you internalise this, the design space opens up. It’s actually fine
for the LLM to read files, access the internet via `httpx`, parse data,
and call into your libraries. The things you want to prevent are writes
to the filesystem, spawning processes, and overwriting important state.
RestrictedPython gives us the mechanism to enforce this: it rewrites the
AST to intercept attribute access, iteration, and item access, so that
every callable goes through an allowlist check.

The allowlist has three tiers. First, a curated subset of the standard
library that has been audited once so every user doesn’t have to repeat
the work: things like `re`, `json`, `itertools`, `math`, `collections`,
`pathlib` (read-only methods), and many more. Second, user-extended
functions registered via
[`allow()`](https://AnswerDotAI.github.io/safepyrun/core.html#allow), so
you can opt in your own project’s functions and methods. Third, an LLM
self-service mechanism: any symbol the LLM creates with a trailing
underscore (like `helper_`) is automatically available in subsequent
calls, letting it build up reusable utilities across a multi-step tool
loop.

## Usage

``` python
from safepyrun import *
```

The main entry point is `pyrun = RunPython()`, which returns an async
function that takes a string of Python code and executes it in the
sandbox. The last expression in the code is returned as the result, and
any `print()` output is captured separately. Errors are caught and
reported rather than crashing the caller.

``` python
pyrun = RunPython()
```

``` python
await pyrun('1+1')
```

    {'result': 2}

You can mix `print()` output with a return value. The printed output
goes to the `stdout` key, and the last expression becomes `result`:

``` python
await pyrun('print("hello"); 1+1')
```

    {'stdout': 'hello\n', 'result': 2}

Modules can be imported. stderr is also captured:

``` python
await pyrun('''
import warnings
warnings.warn('a warning')
"ok"
''')
```

    {'stderr': '<tool>:2: UserWarning: a warning\n', 'result': 'ok'}

A large subset of the standard library is available out of the box –
things like `re`, `json`, `math`, `itertools`, `collections`, `pathlib`
(read-only methods), and many more. These have been audited once so that
every user doesn’t have to repeat the work:

``` python
await pyrun('import re; re.findall(r"\\d+", "there are 3 cats and 10 dogs")')
```

    {'result': ['3', '10']}

The default allowlist covers text and data processing (`re`, `json`,
`csv`, `html`, `textwrap`, `string`, `difflib`, `unicodedata`), math and
numerics (`math`, `cmath`, `statistics`, `decimal`, `fractions`,
`random`, `operator`), data structures (`collections`, `heapq`,
`bisect`, plus methods on all the built-in types), iteration and
functional tools (`itertools`, `functools`), read-only filesystem access
(`pathlib`,
[`os.path`](https://docs.python.org/3/library/os.path.html#module-os.path),
`fnmatch`), date and time (`datetime`, `time`), URL handling and
read-only HTTP
([`urllib.parse`](https://docs.python.org/3/library/urllib.parse.html#module-urllib.parse),
`httpx.get`, `ipaddress`), encoding and serialization (`base64`,
`binascii`, `hashlib`, `zlib`, `pickle`, `struct`), introspection
(`inspect`, `ast`, `keyword`,
[`sys.getsizeof`](https://docs.python.org/3/library/sys.html#sys.getsizeof)),
XML parsing
([`xml.etree.ElementTree`](https://docs.python.org/3/library/xml.etree.elementtree.html#module-xml.etree.ElementTree)),
and various utilities (`contextlib`, `copy`, `dataclasses`, `enum`,
`secrets`, `uuid`, `pprint`, `shlex`, `colorsys`, `traceback`).

### The [`allow()`](https://AnswerDotAI.github.io/safepyrun/core.html#allow) function

Functions you define yourself or import from third-party packages are
not automatically available. If the sandbox encounters an unregistered
callable, it raises an error.

To make a function available, register it with
[`allow()`](https://AnswerDotAI.github.io/safepyrun/core.html#allow):

``` python
def greet(name): return f"Hello, {name}!"
```

``` python
allow('greet')
await pyrun('greet("World")')
```

    {'result': 'Hello, World!'}

The same applies to anything you import from PyPI. For instance, if you
wanted the LLM to be able to call
[`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array),
you would register it with `allow('numpy.array')`.

[`allow()`](https://AnswerDotAI.github.io/safepyrun/core.html#allow)
accepts two forms: strings and dicts. The simplest form is a bare
string, which registers a single name. This works for standalone
functions in the caller’s namespace:

``` python
def double(x): return x * 2
allow('double')
await pyrun('double(21)')
```

    {'result': 42}

For methods on modules or classes, use dotted string syntax. The string
should match how the sandbox will look up the callable, which is
`ClassName.method` or `module.function`:

``` python
import numpy as np
```

``` python
allow('numpy.array', 'numpy.ndarray.sum')
await pyrun('np.array([1,2,3]).sum()')
```

    {'result': 6}

Note that the string must use the actual class or module name as it
appears in Python, not the alias. In the example above, even though the
sandbox code uses `np`, the allowlist entry is `'numpy.array'` because
`numpy` is the module’s real name.

The dict form is a convenient shorthand for registering multiple methods
on the same module or class at once. The key is the actual module or
class object, and the value is a list of method name strings:

``` python
allow({np.ndarray: ['mean', 'reshape', 'tolist']})
await pyrun('np.array([1,2,3,4]).reshape(2,2).mean()')
```

    {'result': 2.5}

The dict form does two things: it registers the class/module name itself
(so it can be called as a constructor or accessed as a namespace), and
it registers each `ClassName.method` pair. You can mix strings and dicts
in a single
[`allow()`](https://AnswerDotAI.github.io/safepyrun/core.html#allow)
call:

``` python
allow('my_func', {np.linalg: ['norm', 'det']})
```

### The `_` suffix convention

There’s a third way callables become available in the sandbox: any
symbol the LLM creates whose name ends with `_` (but doesn’t start with
`_`) is automatically exported back to the caller’s namespace, and is
available in subsequent `pyrun` calls. This means the LLM can build up
reusable helper functions across a multi-step tool loop without
requiring the user to register anything:

``` python
await pyrun('def clean_(s): return s.strip().lower()')
```

``` python
await pyrun('clean_("  Hello World  ")')
```

The exported symbols are real objects in your namespace, not just
available inside the sandbox. This works for variables too, not just
functions:

``` python
await pyrun('result_ = [x**2 for x in range(5)]')
result_
```

    [0, 1, 4, 9, 16]

This is particularly useful in LLM tool loops where the model might need
to define a parsing function in one step and reuse it in several
subsequent steps. Non-suffixed names remain local to the sandbox call
and are not exported.

### Async support

The sandbox is async-native. If the code being executed contains
`await`, `async for`, or `async with` expressions, they work as
expected. Many modern Python libraries and LLM tool-calling frameworks
are async, and you want the sandbox to be able to call into them without
workarounds.

``` python
await pyrun('''
import asyncio
async def fetch(n): return n * 10
await asyncio.gather(fetch(1), fetch(2), fetch(3))
''')
```

    {'result': [10, 20, 30]}
